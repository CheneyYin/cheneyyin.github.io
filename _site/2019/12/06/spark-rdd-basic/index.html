<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI" />
    <meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover">
    <meta name="description" content="这里是 Cheney.Yin 的个人博客">
    <meta name="keywords" content="CHeney.Yin Blog, 博客, 个人网站, 互联网, Web, JavaScript, Database, Hadoop, Spark, Docker, 设计">
    <meta name="theme-color" content="#000000">

    <!-- Open Graph -->
    <meta property="og:title"
        content="Spark RDD 1 --- 基础 - Cheney.Yin的博客 | Cheney Blog">
    
    <meta property="og:type" content="article">
    <meta property="og:description" content="RDD基础
">
    
    <meta property="article:published_time" content=" 2019-12-06T00:00:00Z">
    
    
    <meta property="article:author" content="Cheney.Yin">
    
    
    <meta property="article:tag" content="Spark">
    
    <meta property="article:tag" content="RDD">
    
    <meta property="article:tag" content="数据分区">
    
    <meta property="article:tag" content="闭包">
    
    
    <meta property="og:image" content="http://localhost:4000/img/cheney.jpg">
    <meta property="og:url" content="http://localhost:4000/2019/12/06/spark-rdd-basic/">
    <meta property="og:site_name" content="Cheney.Yin的博客 | Cheney Blog">

    <title>Spark RDD 1 --- 基础 - Cheney.Yin的博客 | Cheney Blog</title>

    <!-- Web App Manifest -->
    <link rel="manifest" href="/pwa/manifest.json">

    <!-- Favicon -->
    <link rel="shortcut icon" href="/img/favicon.ico">

    <!-- Canonical URL -->
    <link rel="canonical" href="http://localhost:4000/2019/12/06/spark-rdd-basic/">

    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href=" /css/bootstrap.min.css">

    <!-- Custom CSS -->
    <link rel="stylesheet" href=" /css/hux-blog.min.css">

    <!-- Custom Fonts -->
    <!-- <link href="http://maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet" type="text/css"> -->
    <!-- Hux change font-awesome CDN to qiniu -->
    <link href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet"
        type="text/css">


    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->
    <!-- ga & ba script hoook -->
    <script></script>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

 </head>

<!-- hack iOS CSS :active style -->
<body ontouchstart="">

    <!-- Navigation -->

    <nav class="navbar navbar-default navbar-custom navbar-fixed-top">
        
        <div class="container-fluid">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="navbar-header page-scroll">
                <button type="button" class="navbar-toggle">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a class="navbar-brand" href="/">Cheney.Yin Blog</a>
            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div id="huxblog_navbar">
                <div class="navbar-collapse">
                    <ul class="nav navbar-nav navbar-right">
                        <li>
                            <a href="/">Home</a>
                        </li>
                        
                        
                        
                        
                        <li>
                            <a href="/about/">About</a>
                        </li>
                        
                        
                        
                        <li>
                            <a href="/archive/">Archive</a>
                        </li>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <li>
                            <a href="/project/">Project</a>
                        </li>
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        <li class="search-icon">
                            <a href="javascript:void(0)">
                                <i class="fa fa-search"></i>
                            </a>
                        </li>
                    </ul>
                </div>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container -->
    </nav>

    <script>
        // Drop Bootstarp low-performance Navbar
        // Use customize navbar with high-quality material design animation
        // in high-perf jank-free CSS3 implementation
        var $body = document.body;
        var $toggle = document.querySelector('.navbar-toggle');
        var $navbar = document.querySelector('#huxblog_navbar');
        var $collapse = document.querySelector('.navbar-collapse');

        var __HuxNav__ = {
            close: function () {
                $navbar.className = " ";
                // wait until animation end.
                setTimeout(function () {
                    // prevent frequently toggle
                    if ($navbar.className.indexOf('in') < 0) {
                        $collapse.style.height = "0px"
                    }
                }, 400)
            },
            open: function () {
                $collapse.style.height = "auto"
                $navbar.className += " in";
            }
        }

        // Bind Event
        $toggle.addEventListener('click', function (e) {
            if ($navbar.className.indexOf('in') > 0) {
                __HuxNav__.close()
            } else {
                __HuxNav__.open()
            }
        })

        /**
         * Since Fastclick is used to delegate 'touchstart' globally
         * to hack 300ms delay in iOS by performing a fake 'click',
         * Using 'e.stopPropagation' to stop 'touchstart' event from 
         * $toggle/$collapse will break global delegation.
         * 
         * Instead, we use a 'e.target' filter to prevent handler
         * added to document close HuxNav.  
         *
         * Also, we use 'click' instead of 'touchstart' as compromise
         */
        document.addEventListener('click', function (e) {
            if (e.target == $toggle) return;
            if (e.target.className == 'icon-bar') return;
            __HuxNav__.close();
        })
    </script>
    <!-- Search -->
<div class="search-page">
  <div class="search-icon-close-container">
    <span class="search-icon-close">
      <i class="fa fa-chevron-down"></i>
    </span>
  </div>
  <div class="search-main container">
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <form></form>
        <input type="text" id="search-input" placeholder="$ grep...">
        </form>
        <div id="search-results" class="mini-post-list"></div>
      </div>
    </div>
  </div>
</div>

    <!-- Post Header -->



<style type="text/css">
    header.intro-header{
        position: relative;
        background-image: url('/img/bg-material.jpg');
        background: ;
    }

    
</style>




<header class="intro-header" >

    <div class="header-mask"></div>
    
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <div class="post-heading">
                    <div class="tags">
                        
                        <a class="tag" href="/archive/?tag=Spark" title="Spark">Spark</a>
                        
                        <a class="tag" href="/archive/?tag=RDD" title="RDD">RDD</a>
                        
                        <a class="tag" href="/archive/?tag=%E6%95%B0%E6%8D%AE%E5%88%86%E5%8C%BA" title="数据分区">数据分区</a>
                        
                        <a class="tag" href="/archive/?tag=%E9%97%AD%E5%8C%85" title="闭包">闭包</a>
                        
                    </div>
                    <h1>Spark RDD 1 --- 基础</h1>
                    
                    <h2 class="subheading">介绍Spark RDD的相关概念和基本操作</h2>
                    <span class="meta">Posted by Cheney.Yin on December 6, 2019</span>
                </div>
            </div>
        </div>
    </div>
</header>







<!-- Post Content -->
<article>
    <div class="container">
        <div class="row">

    <!-- Post Container -->
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                post-container">

                <!-- Multi-Lingual -->
                

				<h1 id="rdd基础">RDD基础</h1>

<p>Spark以弹性分布式数据集作为中心，RDD是容错、具备并且操作的元素集合。</p>

<p>创建RDD的两种方式：</p>

<ol>
  <li>driver程序中，调用<code class="language-plaintext highlighter-rouge">SparkContext.parallelize()</code>.</li>
  <li>从外部存储引入数据集。</li>
</ol>

<h2 id="并行集合">并行集合</h2>

<p>在spark-shell交互模式下，执行如下命令：</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre><span class="k">val</span> <span class="nv">distData</span> <span class="k">=</span> <span class="nv">sc</span><span class="o">.</span><span class="py">parallelize</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span><span class="mi">2</span><span class="o">,</span><span class="mi">4</span><span class="o">,</span><span class="mi">5</span><span class="o">))</span>
<span class="nv">distData</span><span class="o">.</span><span class="py">partitions</span><span class="o">.</span><span class="py">foreach</span><span class="o">(</span><span class="n">x</span> <span class="k">=&gt;</span> <span class="nf">println</span><span class="o">(</span><span class="n">x</span><span class="o">))</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>结果如下：</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre></td><td class="rouge-code"><pre>org.apache.spark.rdd.ParallelCollectionPartition@691
org.apache.spark.rdd.ParallelCollectionPartition@692
org.apache.spark.rdd.ParallelCollectionPartition@693
org.apache.spark.rdd.ParallelCollectionPartition@694
</pre></td></tr></tbody></table></code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">distData</code>拥有4个分区。</p>

<p>执行如下命令求和：</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre><span class="nv">distData</span><span class="o">.</span><span class="py">reduce</span><span class="o">((</span><span class="n">s</span><span class="o">,</span> <span class="n">x</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">s</span> <span class="o">+</span> <span class="n">x</span><span class="o">)</span>
<span class="n">res7</span><span class="k">:</span> <span class="kt">Int</span> <span class="o">=</span> <span class="mi">12</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>并行集合有一个很重要的参数是partitions分区数量，它可以用来切割dataset(数据集)。Spark将在集群中的每个分区上运行一个任务。一般情况下，Spark会尝试根据机器情况来自动设置分区数量。当然，我们也可以指定参数来设置分区数量，如下：</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre></td><td class="rouge-code"><pre><span class="k">val</span> <span class="nv">distData1</span> <span class="k">=</span> <span class="nv">sc</span><span class="o">.</span><span class="py">parallelize</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span><span class="mi">2</span><span class="o">,</span><span class="mi">3</span><span class="o">,</span><span class="mi">4</span><span class="o">,</span><span class="mi">5</span><span class="o">,</span><span class="mi">6</span><span class="o">,</span><span class="mi">7</span><span class="o">,</span><span class="mi">8</span><span class="o">))</span>

<span class="k">val</span> <span class="nv">distData2</span> <span class="k">=</span> <span class="nv">sc</span><span class="o">.</span><span class="py">parallelize</span><span class="o">(</span><span class="nc">Array</span><span class="o">(</span><span class="mi">1</span><span class="o">,</span><span class="mi">2</span><span class="o">,</span><span class="mi">3</span><span class="o">,</span><span class="mi">4</span><span class="o">,</span><span class="mi">5</span><span class="o">,</span><span class="mi">6</span><span class="o">,</span><span class="mi">7</span><span class="o">,</span><span class="mi">8</span><span class="o">),</span> <span class="mi">2</span><span class="o">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>结果如下：</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre></td><td class="rouge-code"><pre>scala&gt; distData1.partitions.foreach(x =&gt; println(x))
org.apache.spark.rdd.ParallelCollectionPartition@6e3
org.apache.spark.rdd.ParallelCollectionPartition@6e4
org.apache.spark.rdd.ParallelCollectionPartition@6e5
org.apache.spark.rdd.ParallelCollectionPartition@6e6

scala&gt; distData2.partitions.foreach(x =&gt; println(x))
org.apache.spark.rdd.ParallelCollectionPartition@70c
org.apache.spark.rdd.ParallelCollectionPartition@70d
</pre></td></tr></tbody></table></code></pre></div></div>

<h2 id="外部数据集">外部数据集</h2>

<p>Spark可以同Hadoop支持的任何存储源中建立分布式数据集，包括本地文件系统，HDFS，Cassandra，HBase，Amazon S3等等。</p>

<p>Spark支持文本文件、SequenceFiles以及任何其它的Hadoop InputFormat。</p>

<p>可以使用SparkContext的textFile方法创建文本文件的RDD。此方法需要一个文件的URI(计算机上的本地路径，hdfs://，s3n://等等URI)，并且读取它们作为一个lines的集合。调试如下：</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
</pre></td><td class="rouge-code"><pre><span class="n">scala</span><span class="o">&gt;</span> <span class="k">val</span> <span class="nv">distFile</span> <span class="k">=</span> <span class="nv">sc</span><span class="o">.</span><span class="py">textFile</span><span class="o">(</span><span class="s">"spark-shell.cmd"</span><span class="o">)</span>
<span class="n">distFile</span><span class="k">:</span> <span class="kt">org.apache.spark.rdd.RDD</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="n">spark</span><span class="o">-</span><span class="nv">shell</span><span class="o">.</span><span class="py">cmd</span> <span class="nc">MapPartitionsRDD</span><span class="o">[</span><span class="err">1</span><span class="o">]</span> <span class="n">at</span> <span class="n">textFile</span> <span class="n">at</span> <span class="o">&lt;</span><span class="n">console</span><span class="k">&gt;:</span><span class="mi">24</span>

<span class="n">scala</span><span class="o">&gt;</span> <span class="nv">distFile</span><span class="o">.</span><span class="py">partitions</span><span class="o">.</span><span class="py">foreach</span><span class="o">(</span><span class="n">x</span> <span class="k">=&gt;</span> <span class="nf">println</span><span class="o">(</span><span class="n">x</span><span class="o">))</span>
<span class="nv">org</span><span class="o">.</span><span class="py">apache</span><span class="o">.</span><span class="py">spark</span><span class="o">.</span><span class="py">rdd</span><span class="o">.</span><span class="py">HadoopPartition</span><span class="k">@</span><span class="mi">3</span><span class="n">c1</span>
<span class="nv">org</span><span class="o">.</span><span class="py">apache</span><span class="o">.</span><span class="py">spark</span><span class="o">.</span><span class="py">rdd</span><span class="o">.</span><span class="py">HadoopPartition</span><span class="k">@</span><span class="mi">3</span><span class="n">c2</span>

<span class="n">scala</span><span class="o">&gt;</span> <span class="k">val</span> <span class="nv">distFile</span> <span class="k">=</span> <span class="nv">sc</span><span class="o">.</span><span class="py">textFile</span><span class="o">(</span><span class="s">"spark-shell.cmd"</span><span class="o">,</span> <span class="mi">4</span><span class="o">)</span>
<span class="n">distFile</span><span class="k">:</span> <span class="kt">org.apache.spark.rdd.RDD</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="n">spark</span><span class="o">-</span><span class="nv">shell</span><span class="o">.</span><span class="py">cmd</span> <span class="nc">MapPartitionsRDD</span><span class="o">[</span><span class="err">3</span><span class="o">]</span> <span class="n">at</span> <span class="n">textFile</span> <span class="n">at</span> <span class="o">&lt;</span><span class="n">console</span><span class="k">&gt;:</span><span class="mi">24</span>

<span class="n">scala</span><span class="o">&gt;</span> <span class="nv">distFile</span><span class="o">.</span><span class="py">partitions</span><span class="o">.</span><span class="py">foreach</span><span class="o">(</span><span class="n">x</span> <span class="k">=&gt;</span> <span class="nf">println</span><span class="o">(</span><span class="n">x</span><span class="o">))</span>
<span class="nv">org</span><span class="o">.</span><span class="py">apache</span><span class="o">.</span><span class="py">spark</span><span class="o">.</span><span class="py">rdd</span><span class="o">.</span><span class="py">HadoopPartition</span><span class="k">@</span><span class="mf">3f</span><span class="n">f</span>
<span class="nv">org</span><span class="o">.</span><span class="py">apache</span><span class="o">.</span><span class="py">spark</span><span class="o">.</span><span class="py">rdd</span><span class="o">.</span><span class="py">HadoopPartition</span><span class="k">@</span><span class="mi">400</span>
<span class="nv">org</span><span class="o">.</span><span class="py">apache</span><span class="o">.</span><span class="py">spark</span><span class="o">.</span><span class="py">rdd</span><span class="o">.</span><span class="py">HadoopPartition</span><span class="k">@</span><span class="mi">401</span>
<span class="nv">org</span><span class="o">.</span><span class="py">apache</span><span class="o">.</span><span class="py">spark</span><span class="o">.</span><span class="py">rdd</span><span class="o">.</span><span class="py">HadoopPartition</span><span class="k">@</span><span class="mi">402</span>

</pre></td></tr></tbody></table></code></pre></div></div>

<p>在创建后，distFile可以使用dataset的操作。通过如下命令统计行数，</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre><span class="n">scala</span><span class="o">&gt;</span> <span class="nv">distFile</span><span class="o">.</span><span class="py">map</span><span class="o">(</span><span class="n">l</span> <span class="k">=&gt;</span> <span class="mi">1</span><span class="o">).</span><span class="py">reduce</span><span class="o">((</span><span class="n">s</span><span class="o">,</span><span class="n">n</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">s</span> <span class="o">+</span> <span class="n">n</span><span class="o">)</span>
<span class="n">res3</span><span class="k">:</span> <span class="kt">Int</span> <span class="o">=</span> <span class="mi">23</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>使用Spark读取文件的注意事项：</p>

<ul>
  <li>
    <p>如果使用本地文件系统路径，所有工作节点的相同路径下该文件必须能够访问。复制文件到所有工作节点上，或者使用共享的网络挂在文件系统。</p>
  </li>
  <li>
    <p>所有Spark中基于文件的输入方法，包括textFile，支持目录、压缩文件或者通配符来操作。例如，</p>

    <div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre></td><td class="rouge-code"><pre>textFile<span class="o">(</span><span class="s2">"/my/directory"</span><span class="o">)</span>
  
textFile<span class="o">(</span><span class="s2">"/my/directory/*.txt"</span><span class="o">)</span>
  
textFile<span class="o">(</span><span class="s2">"/my/directory/*.gz"</span><span class="o">)</span>
</pre></td></tr></tbody></table></code></pre></div>    </div>
  </li>
  <li>
    <p>textFile方法也可以通过第二个可选的参数来控制该文件的分区数量。默认情况下，Spark为文件的每个block创建一个分区（HDFS中块大小默认64M），当然你也可以通过传递一个较大的值来要求一个较高的分区数量。PS.分区数量不能小于块的数量。</p>
  </li>
</ul>

<p>除了文本文件外，Spark的Scala API也支持一些其它的数据格式：</p>
<ul>
  <li>SparkContext.wholeTextFiles可以读取包含多个小文件的目录，并返回它们的每一个(filename, content)对。这与textFile形成对比，它的每一文件中的每一行返回一个记录。</li>
  <li>针对SequenceFiles，使用SparkContext的SequenceFile[K, V]方法，其中K、V指的是它们在文件中的类型。这些应该是Hadoop中Writeable接口的子类，例如IntWritable和Text。此外，Spark可以让您为一些常见的Writables指定原生类型。例如，SequenceFile[Int, String]会自动读取IntWritables和Texts。</li>
  <li>针对其它的Hadoop InputFormats，您可以使用SparkContext。hadoopRDD方法，它接受一个任意JobConf和Input format类、key类和value类。通过相同的方法你可以设置你Hadoop Job的输入源。你还可以使用基于”new”和MapReduce API(org.apache.hadoop.mapreduce)来使用SparkContext.newAPIHadoopRDD以设置InputFormats。</li>
  <li>RDD.saveAsObjectFile和SparkContext.objectFile支持使用简单的序列化的Java Object来保存RDD。虽然这不像Avro这种专用的格式一样高效，但是它提供了一种更简单的方式来保存任何RDD。</li>
</ul>

<h3 id="hadooprdd分区方法">HadoopRDD分区方法</h3>

<table>
  <thead>
    <tr>
      <th> </th>
      <th>#1</th>
      <th>#2</th>
      <th>#3</th>
      <th>#4</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>#1</td>
      <td>a</td>
      <td>b</td>
      <td>c</td>
      <td>d</td>
    </tr>
    <tr>
      <td>#2</td>
      <td>\n</td>
      <td>3</td>
      <td>g</td>
      <td>f</td>
    </tr>
    <tr>
      <td>#3</td>
      <td>v</td>
      <td>e</td>
      <td>t</td>
      <td>d</td>
    </tr>
    <tr>
      <td>#4</td>
      <td>d</td>
      <td>\n</td>
      <td>d</td>
      <td>4</td>
    </tr>
    <tr>
      <td>#5</td>
      <td>\n</td>
      <td>o</td>
      <td>z</td>
      <td>y</td>
    </tr>
    <tr>
      <td>#6</td>
      <td>y</td>
      <td>y</td>
      <td>c</td>
      <td>\n</td>
    </tr>
  </tbody>
</table>

<p>上表现某个文件的存储内容，假设文件内容按照‘\n’划分记录，并且最小分区数为2，那么HadoopRDD的分区方法如下：</p>

<p>HadoopRDD首先会根据文件总长度/最小分区数来预分区，上述文件预分区结果如下：</p>

<p>partition(0) := [#1, #1] -&gt; (#4, #1)</p>

<p>partition(1) := [#4, #1] -&gt; (#7, #1)</p>

<p>然后进行实际分区，实际分区会在预分区的基础上作出调整，并且各个分区的计算是独立的。</p>

<p>首先，确定每个分区的起点。首个分区的起点，如partition(0)，不做调整。非首个分区的起点，需要重新计算，计算方式是从与分区起点开始(不包含该点)，向后搜索，直至找到首个记录分割符或到达文件末尾。若找到分割符，则起点为分割符的后继位置。若计算的起点位置超出文件范围，后者未找到分割符，则分区为空。</p>

<p>然后，确定每个分区的终点，需要从预分区终点(不包含该点)，向后搜索，直至找到首个记录分隔符或到达文件末尾。若找到分割符或到达文件末尾，则终点为搜索停止处的后继位置。</p>

<p>以上述文件为例，</p>

<p>计算起点</p>

<p>partition(0) := [#1, #1] -&gt; (#4, #1)    =&gt;    [#1, #1] -&gt; (#4, #1)</p>

<p>partition(1) := [#4, #1] -&gt; (#7, #1)    =&gt;    [#4, #3] -&gt; (#7, #1)</p>

<p>计算终点</p>

<p>partition(0) := [#1, #1] -&gt; (#4, #1)    =&gt;    [#1, #1] -&gt; (#4, #3)</p>

<p>partition(1) := [#4, #3] -&gt; (#7, #1)    =&gt;    [#4, #3] -&gt; (#7, #1)</p>

<p>若最小分区数为3，则预分区为：</p>

<p>partition(0) := [#1, #1] -&gt; (#3, #1)</p>

<p>partition(1) := [#3, #1] -&gt; (#5, #1)</p>

<p>partition(2) := [#5, #1] -&gt; (#7, #1)</p>

<p>计算起点</p>

<p>partition(0) := [#1, #1] -&gt; (#3, #1)	=&gt;	[#1, #1] -&gt; (#3, #1)</p>

<p>partition(1) := [#3, #1] -&gt; (#5, #1)	=&gt;	[#4, #3] -&gt; (#5, #1)</p>

<p>partition(2) := [#5, #1] -&gt; (#7, #1)	=&gt;	[#7, #1] -&gt; (#5, #1)</p>

<p>计算终点</p>

<p>partition(0) := [#1, #1] -&gt; (#3, #1)	=&gt;	[#1, #1] -&gt; (#4, #3)</p>

<p>partition(1) := [#4, #3] -&gt; (#5, #1)	=&gt;	[#4, #3] -&gt; (#7, #1)</p>

<p>partition(2) := [#7, #1] -&gt; (#5, #1)	=&gt;	[#7, #1] -&gt; (#7, #1)	：为空</p>

<p>若最小分区数为6，则预分区为：</p>

<p>partition(0) := [#1, #1] -&gt; (#2, #1)</p>

<p>partition(1) := [#2, #1] -&gt; (#3, #1)</p>

<p>partition(2) := [#3, #1] -&gt; (#4, #1)</p>

<p>partition(3) := [#4, #1] -&gt; (#5, #1)</p>

<p>partition(4) := [#5, #1] -&gt; (#6, #1)</p>

<p>partition(5) := [#6, #1] -&gt; (#7, #1)</p>

<p>计算</p>

<p>partition(0) := [#1, #1] -&gt; (#2, #1)	=&gt;	[#1, #1] -&gt; (#4, #3)</p>

<p>partition(1) := [#2, #1] -&gt; (#3, #1)	=&gt;	[#4, #3] -&gt; (#7, #1)</p>

<p>partition(2) := [#3, #1] -&gt; (#4, #1)	=&gt;	[#4, #3] -&gt; (#7, #1)</p>

<p>partition(3) := [#4, #1] -&gt; (#5, #1)	=&gt;	[#4, #3] -&gt; (#7, #1)</p>

<p>partition(4) := [#5, #1] -&gt; (#6, #1)	=&gt;	[#7, #1] -&gt;  (#7 #1)</p>

<p>partition(5) := [#6, #1] -&gt; (#7, #1)	=&gt;	[#7, #1] -&gt; (#7, #1)</p>

<p>partition(1)、partition(2)、partition(3)等价，partition(4)、partition(5)为空。</p>

<h2 id="rdd操作">RDD操作</h2>

<p>如下命令使用RDD的基本操作实现了文件长度统计，如下：</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre></td><td class="rouge-code"><pre><span class="n">scala</span><span class="o">&gt;</span> <span class="k">val</span> <span class="nv">distFile</span> <span class="k">=</span> <span class="nv">sc</span><span class="o">.</span><span class="py">textFile</span><span class="o">(</span><span class="s">"spark-shell.cmd"</span><span class="o">)</span>
<span class="n">distFile</span><span class="k">:</span> <span class="kt">org.apache.spark.rdd.RDD</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="n">spark</span><span class="o">-</span><span class="nv">shell</span><span class="o">.</span><span class="py">cmd</span> <span class="nc">MapPartitionsRDD</span><span class="o">[</span><span class="err">11</span><span class="o">]</span> <span class="n">at</span> <span class="n">textFile</span> <span class="n">at</span> <span class="o">&lt;</span><span class="n">console</span><span class="k">&gt;:</span><span class="mi">24</span>

<span class="n">scala</span><span class="o">&gt;</span> <span class="nv">distFile</span><span class="o">.</span><span class="py">map</span><span class="o">(</span><span class="n">l</span> <span class="k">=&gt;</span> <span class="nv">l</span><span class="o">.</span><span class="py">length</span><span class="o">).</span><span class="py">reduce</span><span class="o">((</span><span class="n">s</span><span class="o">,</span> <span class="n">n</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">s</span> <span class="o">+</span> <span class="n">n</span><span class="o">)</span>
<span class="n">res7</span><span class="k">:</span> <span class="kt">Int</span> <span class="o">=</span> <span class="mi">987</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>首先定义了一个基本的RDD，但是这个数据集没有立即加载到内存。</p>

<p><code class="language-plaintext highlighter-rouge">distFile.map(l =&gt; l.length)</code>是map transformation操作。由于laziness，操作不会立即执行。</p>

<p>最后的<code class="language-plaintext highlighter-rouge">reduce</code>操作，是一个action。此时，Spark分发计算任务到不同的机器上运行，每个机器都运行在map的一部分，并在本地运行reduce，仅返回聚合结果后给驱动程序。</p>

<p>若希望后续再次使用<code class="language-plaintext highlighter-rouge">distFile</code>，可以执行如下命令：</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre><span class="n">scala</span><span class="o">&gt;</span> <span class="nv">distFile</span><span class="o">.</span><span class="py">persist</span><span class="o">()</span>
<span class="n">res8</span><span class="k">:</span> <span class="kt">distFile.</span><span class="k">type</span> <span class="o">=</span> <span class="n">spark</span><span class="o">-</span><span class="nv">shell</span><span class="o">.</span><span class="py">cmd</span> <span class="nc">MapPartitionsRDD</span><span class="o">[</span><span class="err">11</span><span class="o">]</span> <span class="n">at</span> <span class="n">textFile</span> <span class="n">at</span> <span class="o">&lt;</span><span class="n">console</span><span class="k">&gt;:</span><span class="mi">24</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>这样在其它同<code class="language-plaintext highlighter-rouge">reduce</code>类似的action操作执行前，<code class="language-plaintext highlighter-rouge">distFile</code>不需要重新计算。</p>

<h2 id="向spark传递函数">向Spark传递函数</h2>

<p>当驱动程序在集群上运行时，Spark的API在很大程度上依赖于传递函数。有俩各种推荐方式来做到这一点：</p>

<ul>
  <li>
    <p>匿名函数的语法Anonymous Function syntax， 它可以用于短的代码片断。</p>
  </li>
  <li>
    <p>在全局单例对象中的静态方法。例如，你可以定义对象MyFunctions然后传递MyFunctions.func1，具体如下：</p>

    <div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre></td><td class="rouge-code"><pre><span class="n">scala</span><span class="o">&gt;</span> <span class="k">object</span> <span class="nc">MyFunctions</span> <span class="o">{</span>
     <span class="o">|</span> <span class="k">def</span> <span class="nf">func1</span><span class="o">(</span><span class="n">s</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span><span class="k">:</span> <span class="kt">String</span> <span class="o">=</span> <span class="o">{</span>
     <span class="o">|</span> <span class="k">return</span> <span class="n">s</span> <span class="o">+</span> <span class="s">"_hello_"</span><span class="o">;</span>
     <span class="o">|</span> <span class="o">}</span>
     <span class="o">|</span> <span class="o">}</span>
<span class="n">defined</span> <span class="k">object</span> <span class="nc">MyFunctions</span>
  
<span class="n">scala</span><span class="o">&gt;</span> <span class="k">val</span> <span class="nv">distFile</span> <span class="k">=</span> <span class="nv">sc</span><span class="o">.</span><span class="py">textFile</span><span class="o">(</span><span class="s">"spark-shell.cmd"</span><span class="o">)</span>
<span class="n">distFile</span><span class="k">:</span> <span class="kt">org.apache.spark.rdd.RDD</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="n">spark</span><span class="o">-</span><span class="nv">shell</span><span class="o">.</span><span class="py">cmd</span> <span class="nc">MapPartitionsRDD</span><span class="o">[</span><span class="err">1</span><span class="o">]</span> <span class="n">at</span> <span class="n">textFile</span> <span class="n">at</span> <span class="o">&lt;</span><span class="n">console</span><span class="k">&gt;:</span><span class="mi">24</span>
  
<span class="n">scala</span><span class="o">&gt;</span> <span class="nv">distFile</span><span class="o">.</span><span class="py">map</span><span class="o">(</span><span class="nv">MyFunctions</span><span class="o">.</span><span class="py">func1</span><span class="o">).</span><span class="py">collect</span><span class="o">()</span>
<span class="n">res0</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">(</span><span class="nd">@echo</span> <span class="n">off_hello_</span><span class="o">,</span> <span class="nc">_hello_</span><span class="o">,</span> <span class="n">rem_hello_</span><span class="o">,</span> <span class="n">rem</span> <span class="nc">Licensed</span> <span class="n">to</span> <span class="n">the</span> <span class="nc">Apache</span> <span class="nc">Software</span> <span class="nc">Foundation</span> <span class="o">(</span><span class="nc">ASF</span><span class="o">)</span> <span class="n">under</span> <span class="n">one</span> <span class="n">or</span> <span class="n">more_hello_</span><span class="o">,</span> <span class="n">rem</span> <span class="n">contributor</span> <span class="n">license</span> <span class="n">agreements</span><span class="o">.</span>  <span class="nc">See</span> <span class="n">the</span> <span class="nc">NOTICE</span> <span class="n">file</span> <span class="n">distributed</span> <span class="n">with_hello_</span><span class="o">,</span> <span class="n">rem</span> <span class="k">this</span> <span class="n">work</span> <span class="k">for</span> <span class="n">additional</span> <span class="n">information</span> <span class="n">regarding</span> <span class="n">copyright</span> <span class="nv">ownership</span><span class="o">.</span><span class="py">_hello_</span><span class="o">,</span> <span class="n">rem</span> <span class="nc">The</span> <span class="nc">ASF</span> <span class="n">licenses</span> <span class="k">this</span> <span class="n">file</span> <span class="n">to</span> <span class="nc">You</span> <span class="n">under</span> <span class="n">the</span> <span class="nc">Apache</span> <span class="nc">License</span><span class="o">,</span> <span class="nc">Version</span> <span class="mf">2.0</span><span class="nc">_hello_</span><span class="o">,</span> <span class="nf">rem</span> <span class="o">(</span><span class="n">the</span> <span class="s">"License"</span><span class="o">);</span> <span class="n">you</span> <span class="n">may</span> <span class="n">not</span> <span class="n">use</span> <span class="k">this</span> <span class="n">file</span> <span class="n">except</span> <span class="n">in</span> <span class="n">compliance</span> <span class="n">with_hello_</span><span class="o">,</span> <span class="n">rem</span> <span class="n">the</span> <span class="nc">License</span><span class="o">.</span>  <span class="nc">You</span> <span class="n">may</span> <span class="n">obtain</span> <span class="n">a</span> <span class="n">copy</span> <span class="n">of</span> <span class="n">the</span> <span class="nc">License</span> <span class="n">at_hello_</span><span class="o">,</span> <span class="n">rem_hello_</span><span class="o">,</span> <span class="n">rem</span>    <span class="n">http</span><span class="o">://</span><span class="nv">www</span><span class="o">.</span><span class="py">apache</span><span class="o">.</span><span class="py">org</span><span class="o">/</span><span class="n">licenses</span><span class="o">/</span><span class="nc">LICENSE</span><span class="o">-</span><span class="mf">2.0</span><span class="nc">_hello_</span><span class="o">,</span> <span class="n">rem_hello_</span><span class="o">,</span> <span class="n">rem</span> <span class="nc">Unless</span> <span class="n">required</span> <span class="n">by</span> <span class="n">applicable</span> <span class="n">law</span> <span class="n">or</span> <span class="n">agreed</span> <span class="n">to</span> <span class="n">in</span> <span class="n">writing</span><span class="o">,</span> <span class="n">software_hello_</span><span class="o">,</span> <span class="n">rem</span> <span class="n">distributed</span> <span class="n">under</span> <span class="n">the</span> <span class="nc">License</span> <span class="n">is</span> <span class="n">distributed</span> <span class="n">on</span> <span class="n">an</span> <span class="s">"AS IS"</span> <span class="nc">BASIS</span><span class="o">,</span><span class="nc">_hello_</span><span class="o">,</span> <span class="n">rem</span> <span class="nc">WITHOUT</span> <span class="nc">WARRAN</span><span class="o">...</span>
</pre></td></tr></tbody></table></code></pre></div>    </div>

    <p>注意，虽然也可以传递一个类的实例的方法的引用，这需要发送整个对象，包括类的其它方法。例如，考虑：</p>
  </li>
</ul>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre></td><td class="rouge-code"><pre><span class="n">scala</span><span class="o">&gt;</span> <span class="k">class</span> <span class="nc">MyClass</span> <span class="k">extends</span> <span class="nc">Serializable</span> <span class="o">{</span> 
     <span class="o">|</span>   <span class="k">import</span> <span class="nn">org.apache.spark.rdd.RDD</span>
     <span class="o">|</span>   <span class="k">def</span> <span class="nf">func1</span><span class="o">(</span><span class="n">s</span><span class="k">:</span> <span class="kt">String</span><span class="o">)</span><span class="k">:</span> <span class="kt">String</span> <span class="o">=</span> <span class="o">{</span> <span class="k">return</span> <span class="n">s</span> <span class="o">+</span> <span class="s">"_hello_"</span><span class="o">;}</span>
     <span class="o">|</span>   <span class="k">def</span> <span class="nf">doStuff</span><span class="o">(</span><span class="n">rdd</span><span class="k">:</span><span class="kt">RDD</span><span class="o">[</span><span class="kt">String</span><span class="o">])</span><span class="k">:</span> <span class="kt">RDD</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span><span class="nv">rdd</span><span class="o">.</span><span class="py">map</span><span class="o">(</span><span class="n">func1</span><span class="o">)}</span>
     <span class="o">|</span>   <span class="o">}</span>
<span class="n">defined</span> <span class="k">class</span> <span class="nc">MyClass</span>

<span class="n">scala</span><span class="o">&gt;</span> <span class="k">val</span> <span class="nv">myInstance01</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">MyClass</span><span class="o">()</span>
<span class="n">myInstance01</span><span class="k">:</span> <span class="kt">MyClass</span> <span class="o">=</span> <span class="nc">MyClass</span><span class="k">@</span><span class="mi">259</span><span class="n">ae1a9</span>

<span class="n">scala</span><span class="o">&gt;</span> <span class="nv">myInstance01</span><span class="o">.</span><span class="py">doStuff</span><span class="o">(</span><span class="n">distFile</span><span class="o">).</span><span class="py">collect</span><span class="o">()</span>
<span class="n">res4</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">(</span><span class="nd">@echo</span> <span class="n">off_hello_</span><span class="o">,</span> <span class="nc">_hello_</span><span class="o">,</span> <span class="n">rem_hello_</span><span class="o">,</span> <span class="n">rem</span> <span class="nc">Licensed</span> <span class="n">to</span> <span class="n">the</span> <span class="nc">Apache</span> <span class="nc">Software</span> <span class="nc">Foundation</span> <span class="o">(</span><span class="nc">ASF</span><span class="o">)</span> <span class="n">under</span> <span class="n">one</span> <span class="n">or</span> <span class="n">more_hello_</span><span class="o">,</span> <span class="n">rem</span> <span class="n">contributor</span> <span class="n">license</span> <span class="n">agreements</span><span class="o">.</span>  <span class="nc">See</span> <span class="n">the</span> <span class="nc">NOTICE</span> <span class="n">file</span> <span class="n">distributed</span> <span class="n">with_hello_</span><span class="o">,</span> <span class="n">rem</span> <span class="k">this</span> <span class="n">work</span> <span class="k">for</span> <span class="n">additional</span> <span class="n">information</span> <span class="n">regarding</span> <span class="n">copyright</span> <span class="nv">ownership</span><span class="o">.</span><span class="py">_hello_</span><span class="o">,</span> <span class="n">rem</span> <span class="nc">The</span> <span class="nc">ASF</span> <span class="n">licenses</span> <span class="k">this</span> <span class="n">file</span> <span class="n">to</span> <span class="nc">You</span> <span class="n">under</span> <span class="n">the</span> <span class="nc">Apache</span> <span class="nc">License</span><span class="o">,</span> <span class="nc">Version</span> <span class="mf">2.0</span><span class="nc">_hello_</span><span class="o">,</span> <span class="nf">rem</span> <span class="o">(</span><span class="n">the</span> <span class="s">"License"</span><span class="o">);</span> <span class="n">you</span> <span class="n">may</span> <span class="n">not</span> <span class="n">use</span> <span class="k">this</span> <span class="n">file</span> <span class="n">except</span> <span class="n">in</span> <span class="n">compliance</span> <span class="n">with_hello_</span><span class="o">,</span> <span class="n">rem</span> <span class="n">the</span> <span class="nc">License</span><span class="o">.</span>  <span class="nc">You</span> <span class="n">may</span> <span class="n">obtain</span> <span class="n">a</span> <span class="n">copy</span> <span class="n">of</span> <span class="n">the</span> <span class="nc">License</span> <span class="n">at_hello_</span><span class="o">,</span> <span class="n">rem_hello_</span><span class="o">,</span> <span class="n">rem</span>    <span class="n">http</span><span class="o">://</span><span class="nv">www</span><span class="o">.</span><span class="py">apache</span><span class="o">.</span><span class="py">org</span><span class="o">/</span><span class="n">licenses</span><span class="o">/</span><span class="nc">LICENSE</span><span class="o">-</span><span class="mf">2.0</span><span class="nc">_hello_</span><span class="o">,</span> <span class="n">rem_hello_</span><span class="o">,</span> <span class="n">rem</span> <span class="nc">Unless</span> <span class="n">required</span> <span class="n">by</span> <span class="n">applicable</span> <span class="n">law</span> <span class="n">or</span> <span class="n">agreed</span> <span class="n">to</span> <span class="n">in</span> <span class="n">writing</span><span class="o">,</span> <span class="n">software_hello_</span><span class="o">,</span> <span class="n">rem</span> <span class="n">distributed</span> <span class="n">under</span> <span class="n">the</span> <span class="nc">License</span> <span class="n">is</span> <span class="n">distributed</span> <span class="n">on</span> <span class="n">an</span> <span class="s">"AS IS"</span> <span class="nc">BASIS</span><span class="o">,</span><span class="nc">_hello_</span><span class="o">,</span> <span class="n">rem</span> <span class="nc">WITHOUT</span> <span class="nc">WARRAN</span><span class="o">...</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>注意，这里<code class="language-plaintext highlighter-rouge">class MyClass extends Serializable</code>，没有继承将导致对象无法在集群内发送传输，驱动程序抛出如下异常：</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
</pre></td><td class="rouge-code"><pre><span class="nv">org</span><span class="o">.</span><span class="py">apache</span><span class="o">.</span><span class="py">spark</span><span class="o">.</span><span class="py">SparkException</span><span class="k">:</span> <span class="kt">Task</span> <span class="kt">not</span> <span class="kt">serializable</span>
  <span class="n">at</span> <span class="nv">org</span><span class="o">.</span><span class="py">apache</span><span class="o">.</span><span class="py">spark</span><span class="o">.</span><span class="py">util</span><span class="o">.</span><span class="py">ClosureCleaner$</span><span class="o">.</span><span class="py">ensureSerializable</span><span class="o">(</span><span class="nv">ClosureCleaner</span><span class="o">.</span><span class="py">scala</span><span class="k">:</span><span class="err">340</span><span class="o">)</span>
  <span class="n">at</span> <span class="nv">org</span><span class="o">.</span><span class="py">apache</span><span class="o">.</span><span class="py">spark</span><span class="o">.</span><span class="py">util</span><span class="o">.</span><span class="py">ClosureCleaner$</span><span class="o">.</span><span class="py">org$apache$spark$util$ClosureCleaner$$clean</span><span class="o">(</span><span class="nv">ClosureCleaner</span><span class="o">.</span><span class="py">scala</span><span class="k">:</span><span class="err">330</span><span class="o">)</span>
  <span class="n">at</span> <span class="nv">org</span><span class="o">.</span><span class="py">apache</span><span class="o">.</span><span class="py">spark</span><span class="o">.</span><span class="py">util</span><span class="o">.</span><span class="py">ClosureCleaner$</span><span class="o">.</span><span class="py">clean</span><span class="o">(</span><span class="nv">ClosureCleaner</span><span class="o">.</span><span class="py">scala</span><span class="k">:</span><span class="err">156</span><span class="o">)</span>
  <span class="n">at</span> <span class="nv">org</span><span class="o">.</span><span class="py">apache</span><span class="o">.</span><span class="py">spark</span><span class="o">.</span><span class="py">SparkContext</span><span class="o">.</span><span class="py">clean</span><span class="o">(</span><span class="nv">SparkContext</span><span class="o">.</span><span class="py">scala</span><span class="k">:</span><span class="err">2294</span><span class="o">)</span>
  <span class="n">at</span> <span class="nv">org</span><span class="o">.</span><span class="py">apache</span><span class="o">.</span><span class="py">spark</span><span class="o">.</span><span class="py">rdd</span><span class="o">.</span><span class="py">RDD$$anonfun$map$1</span><span class="o">.</span><span class="py">apply</span><span class="o">(</span><span class="nv">RDD</span><span class="o">.</span><span class="py">scala</span><span class="k">:</span><span class="err">370</span><span class="o">)</span>
  <span class="n">at</span> <span class="nv">org</span><span class="o">.</span><span class="py">apache</span><span class="o">.</span><span class="py">spark</span><span class="o">.</span><span class="py">rdd</span><span class="o">.</span><span class="py">RDD$$anonfun$map$1</span><span class="o">.</span><span class="py">apply</span><span class="o">(</span><span class="nv">RDD</span><span class="o">.</span><span class="py">scala</span><span class="k">:</span><span class="err">369</span><span class="o">)</span>
  <span class="n">at</span> <span class="nv">org</span><span class="o">.</span><span class="py">apache</span><span class="o">.</span><span class="py">spark</span><span class="o">.</span><span class="py">rdd</span><span class="o">.</span><span class="py">RDDOperationScope$</span><span class="o">.</span><span class="py">withScope</span><span class="o">(</span><span class="nv">RDDOperationScope</span><span class="o">.</span><span class="py">scala</span><span class="k">:</span><span class="err">151</span><span class="o">)</span>
  <span class="n">at</span> <span class="nv">org</span><span class="o">.</span><span class="py">apache</span><span class="o">.</span><span class="py">spark</span><span class="o">.</span><span class="py">rdd</span><span class="o">.</span><span class="py">RDDOperationScope$</span><span class="o">.</span><span class="py">withScope</span><span class="o">(</span><span class="nv">RDDOperationScope</span><span class="o">.</span><span class="py">scala</span><span class="k">:</span><span class="err">112</span><span class="o">)</span>
  <span class="n">at</span> <span class="nv">org</span><span class="o">.</span><span class="py">apache</span><span class="o">.</span><span class="py">spark</span><span class="o">.</span><span class="py">rdd</span><span class="o">.</span><span class="py">RDD</span><span class="o">.</span><span class="py">withScope</span><span class="o">(</span><span class="nv">RDD</span><span class="o">.</span><span class="py">scala</span><span class="k">:</span><span class="err">362</span><span class="o">)</span>
  <span class="n">at</span> <span class="nv">org</span><span class="o">.</span><span class="py">apache</span><span class="o">.</span><span class="py">spark</span><span class="o">.</span><span class="py">rdd</span><span class="o">.</span><span class="py">RDD</span><span class="o">.</span><span class="py">map</span><span class="o">(</span><span class="nv">RDD</span><span class="o">.</span><span class="py">scala</span><span class="k">:</span><span class="err">369</span><span class="o">)</span>
  <span class="n">at</span> <span class="nv">MyClass</span><span class="o">.</span><span class="py">doStuff</span><span class="o">(&lt;</span><span class="n">console</span><span class="k">&gt;:</span><span class="mi">14</span><span class="o">)</span>
  <span class="o">...</span> <span class="mi">48</span> <span class="n">elided</span>
<span class="nc">Caused</span> <span class="n">by</span><span class="k">:</span> <span class="kt">java.io.NotSerializableException:</span> <span class="kt">MyClass</span>
<span class="nc">Serialization</span> <span class="n">stack</span><span class="k">:</span>
	<span class="kt">-</span> <span class="kt">object</span> <span class="kt">not</span> <span class="kt">serializable</span> <span class="o">(</span><span class="kt">class:</span> <span class="kt">MyClass</span><span class="o">,</span> <span class="kt">value:</span> <span class="kt">MyClass@</span><span class="err">73476</span><span class="kt">e2d</span><span class="o">)</span>
	<span class="o">-</span> <span class="nf">field</span> <span class="o">(</span><span class="n">class</span><span class="k">:</span> <span class="kt">MyClass$$anonfun$doStuff$1</span><span class="o">,</span> <span class="n">name</span><span class="k">:</span> <span class="kt">$outer</span><span class="o">,</span> <span class="n">type</span><span class="k">:</span> <span class="kt">class</span> <span class="kt">MyClass</span><span class="o">)</span>
	<span class="o">-</span> <span class="k">object</span> <span class="o">(</span><span class="k">class</span> <span class="nc">MyClass$$anonfun$doStuff$1</span><span class="o">,</span> <span class="o">&lt;</span><span class="n">function1</span><span class="o">&gt;)</span>
  <span class="n">at</span> <span class="nv">org</span><span class="o">.</span><span class="py">apache</span><span class="o">.</span><span class="py">spark</span><span class="o">.</span><span class="py">serializer</span><span class="o">.</span><span class="py">SerializationDebugger$</span><span class="o">.</span><span class="py">improveException</span><span class="o">(</span><span class="nv">SerializationDebugger</span><span class="o">.</span><span class="py">scala</span><span class="k">:</span><span class="err">40</span><span class="o">)</span>
  <span class="n">at</span> <span class="nv">org</span><span class="o">.</span><span class="py">apache</span><span class="o">.</span><span class="py">spark</span><span class="o">.</span><span class="py">serializer</span><span class="o">.</span><span class="py">JavaSerializationStream</span><span class="o">.</span><span class="py">writeObject</span><span class="o">(</span><span class="nv">JavaSerializer</span><span class="o">.</span><span class="py">scala</span><span class="k">:</span><span class="err">46</span><span class="o">)</span>
  <span class="n">at</span> <span class="nv">org</span><span class="o">.</span><span class="py">apache</span><span class="o">.</span><span class="py">spark</span><span class="o">.</span><span class="py">serializer</span><span class="o">.</span><span class="py">JavaSerializerInstance</span><span class="o">.</span><span class="py">serialize</span><span class="o">(</span><span class="nv">JavaSerializer</span><span class="o">.</span><span class="py">scala</span><span class="k">:</span><span class="err">100</span><span class="o">)</span>
  <span class="n">at</span> <span class="nv">org</span><span class="o">.</span><span class="py">apache</span><span class="o">.</span><span class="py">spark</span><span class="o">.</span><span class="py">util</span><span class="o">.</span><span class="py">ClosureCleaner$</span><span class="o">.</span><span class="py">ensureSerializable</span><span class="o">(</span><span class="nv">ClosureCleaner</span><span class="o">.</span><span class="py">scala</span><span class="k">:</span><span class="err">337</span><span class="o">)</span>
  <span class="o">...</span> <span class="mi">58</span> <span class="n">more</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>类似地，</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre></td><td class="rouge-code"><pre><span class="n">scala</span><span class="o">&gt;</span> <span class="k">class</span> <span class="nc">MyClass</span> <span class="k">extends</span> <span class="nc">Serializable</span><span class="o">{</span>
     <span class="o">|</span>   <span class="k">import</span> <span class="nn">org.apache.spark.rdd.RDD</span>
     <span class="o">|</span>   <span class="k">val</span> <span class="nv">field</span> <span class="k">=</span> <span class="s">"Hello"</span>
     <span class="o">|</span>   <span class="k">def</span> <span class="nf">doStuff</span><span class="o">(</span><span class="n">rdd</span><span class="k">:</span> <span class="kt">RDD</span><span class="o">[</span><span class="kt">String</span><span class="o">])</span><span class="k">:</span> <span class="kt">RDD</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span> <span class="nv">rdd</span><span class="o">.</span><span class="py">map</span><span class="o">(</span><span class="n">x</span> <span class="k">=&gt;</span> <span class="n">field</span> <span class="o">+</span> <span class="n">x</span><span class="o">)</span> <span class="o">}</span>
     <span class="o">|</span> <span class="o">}</span>
<span class="n">defined</span> <span class="k">class</span> <span class="nc">MyClass</span>

<span class="n">scala</span><span class="o">&gt;</span> <span class="k">val</span> <span class="nv">myInstance01</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">MyClass</span><span class="o">()</span>
<span class="n">myInstance01</span><span class="k">:</span> <span class="kt">MyClass</span> <span class="o">=</span> <span class="nc">MyClass</span><span class="k">@</span><span class="mi">2</span><span class="n">c78771b</span>

<span class="n">scala</span><span class="o">&gt;</span> <span class="nv">myInstance01</span><span class="o">.</span><span class="py">doStuff</span><span class="o">(</span><span class="n">distFile</span><span class="o">).</span><span class="py">collect</span><span class="o">()</span>
<span class="n">res6</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">(</span><span class="nc">Hello</span><span class="nd">@echo</span> <span class="n">off</span><span class="o">,</span> <span class="nc">Hello</span><span class="o">,</span> <span class="nc">Hellorem</span><span class="o">,</span> <span class="nc">Hellorem</span> <span class="nc">Licensed</span> <span class="n">to</span> <span class="n">the</span> <span class="nc">Apache</span> <span class="nc">Software</span> <span class="nc">Foundation</span> <span class="o">(</span><span class="nc">ASF</span><span class="o">)</span> <span class="n">under</span> <span class="n">one</span> <span class="n">or</span> <span class="n">more</span><span class="o">,</span> <span class="nc">Hellorem</span> <span class="n">contributor</span> <span class="n">license</span> <span class="n">agreements</span><span class="o">.</span>  <span class="nc">See</span> <span class="n">the</span> <span class="nc">NOTICE</span> <span class="n">file</span> <span class="n">distributed</span> <span class="k">with</span><span class="o">,</span> <span class="nc">Hellorem</span> <span class="k">this</span> <span class="n">work</span> <span class="k">for</span> <span class="n">additional</span> <span class="n">information</span> <span class="n">regarding</span> <span class="n">copyright</span> <span class="n">ownership</span><span class="o">.,</span> <span class="nc">Hellorem</span> <span class="nc">The</span> <span class="nc">ASF</span> <span class="n">licenses</span> <span class="k">this</span> <span class="n">file</span> <span class="n">to</span> <span class="nc">You</span> <span class="n">under</span> <span class="n">the</span> <span class="nc">Apache</span> <span class="nc">License</span><span class="o">,</span> <span class="nc">Version</span> <span class="mf">2.0</span><span class="o">,</span> <span class="nc">Hellorem</span> <span class="o">(</span><span class="n">the</span> <span class="s">"License"</span><span class="o">);</span> <span class="n">you</span> <span class="n">may</span> <span class="n">not</span> <span class="n">use</span> <span class="k">this</span> <span class="n">file</span> <span class="n">except</span> <span class="n">in</span> <span class="n">compliance</span> <span class="k">with</span><span class="o">,</span> <span class="nc">Hellorem</span> <span class="n">the</span> <span class="nc">License</span><span class="o">.</span>  <span class="nc">You</span> <span class="n">may</span> <span class="n">obtain</span> <span class="n">a</span> <span class="n">copy</span> <span class="n">of</span> <span class="n">the</span> <span class="nc">License</span> <span class="n">at</span><span class="o">,</span> <span class="nc">Hellorem</span><span class="o">,</span> <span class="nc">Hellorem</span>    <span class="n">http</span><span class="o">://</span><span class="nv">www</span><span class="o">.</span><span class="py">apache</span><span class="o">.</span><span class="py">org</span><span class="o">/</span><span class="n">licenses</span><span class="o">/</span><span class="nc">LICENSE</span><span class="o">-</span><span class="mf">2.0</span><span class="o">,</span> <span class="nc">Hellorem</span><span class="o">,</span> <span class="nc">Hellorem</span> <span class="nc">Unless</span> <span class="n">required</span> <span class="n">by</span> <span class="n">applicable</span> <span class="n">law</span> <span class="n">or</span> <span class="n">agreed</span> <span class="n">to</span> <span class="n">in</span> <span class="n">writing</span><span class="o">,</span> <span class="n">software</span><span class="o">,</span> <span class="nc">Hellorem</span> <span class="n">distributed</span> <span class="n">under</span> <span class="n">the</span> <span class="nc">License</span> <span class="n">is</span> <span class="n">distributed</span> <span class="n">on</span> <span class="n">an</span> <span class="s">"AS IS"</span> <span class="nc">BASIS</span><span class="o">,,</span> <span class="nc">Hellorem</span> <span class="nc">WITHOUT</span> <span class="nc">WARRANTIES</span> <span class="nc">OR</span> <span class="nc">CONDITIONS</span> <span class="nc">OF</span> <span class="n">A</span><span class="o">...</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>同样需要继承<code class="language-plaintext highlighter-rouge">Serializable</code>，这是由于<code class="language-plaintext highlighter-rouge">def doStuff(rdd:RDD[String]): RDD[String] = {rdd.map(func1)}</code>和<code class="language-plaintext highlighter-rouge">def doStuff(rdd: RDD[String]): RDD[String] = { rdd.map(x =&gt; field + x) }</code>，在<code class="language-plaintext highlighter-rouge">map</code>算子中都需要访问对象。如下方式则不必继承<code class="language-plaintext highlighter-rouge">Serializable</code>，</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
</pre></td><td class="rouge-code"><pre><span class="n">scala</span><span class="o">&gt;</span> <span class="k">class</span> <span class="nc">MyClass</span> <span class="o">{</span>
     <span class="o">|</span>   <span class="k">import</span> <span class="nn">org.apache.spark.rdd.RDD</span>
     <span class="o">|</span>   <span class="k">val</span> <span class="nv">field</span> <span class="k">=</span> <span class="s">"Hello"</span>
     <span class="o">|</span>   <span class="k">def</span> <span class="nf">doStuff</span><span class="o">(</span><span class="n">rdd</span><span class="k">:</span> <span class="kt">RDD</span><span class="o">[</span><span class="kt">String</span><span class="o">])</span><span class="k">:</span> <span class="kt">RDD</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="o">{</span> 
     <span class="o">|</span>   <span class="k">val</span> <span class="nv">field_</span> <span class="k">=</span> <span class="k">this</span><span class="o">.</span><span class="py">field</span>
     <span class="o">|</span>   <span class="nv">rdd</span><span class="o">.</span><span class="py">map</span><span class="o">(</span><span class="n">x</span> <span class="k">=&gt;</span> <span class="n">field_</span> <span class="o">+</span> <span class="n">x</span><span class="o">)</span> 
     <span class="o">|</span>   <span class="o">}</span>
     <span class="o">|</span> <span class="o">}</span>
<span class="n">defined</span> <span class="k">class</span> <span class="nc">MyClass</span>

<span class="n">scala</span><span class="o">&gt;</span> <span class="k">val</span> <span class="nv">myInstance01</span> <span class="k">=</span> <span class="k">new</span> <span class="nc">MyClass</span><span class="o">()</span>
<span class="n">myInstance01</span><span class="k">:</span> <span class="kt">MyClass</span> <span class="o">=</span> <span class="nc">MyClass</span><span class="k">@</span><span class="mi">3</span><span class="n">aede2ff</span>

<span class="n">scala</span><span class="o">&gt;</span> <span class="nv">myInstance01</span><span class="o">.</span><span class="py">doStuff</span><span class="o">(</span><span class="n">distFile</span><span class="o">).</span><span class="py">collect</span><span class="o">()</span>
<span class="n">res7</span><span class="k">:</span> <span class="kt">Array</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="nc">Array</span><span class="o">(</span><span class="nc">Hello</span><span class="nd">@echo</span> <span class="n">off</span><span class="o">,</span> <span class="nc">Hello</span><span class="o">,</span> <span class="nc">Hellorem</span><span class="o">,</span> <span class="nc">Hellorem</span> <span class="nc">Licensed</span> <span class="n">to</span> <span class="n">the</span> <span class="nc">Apache</span> <span class="nc">Software</span> <span class="nc">Foundation</span> <span class="o">(</span><span class="nc">ASF</span><span class="o">)</span> <span class="n">under</span> <span class="n">one</span> <span class="n">or</span> <span class="n">more</span><span class="o">,</span> <span class="nc">Hellorem</span> <span class="n">contributor</span> <span class="n">license</span> <span class="n">agreements</span><span class="o">.</span>  <span class="nc">See</span> <span class="n">the</span> <span class="nc">NOTICE</span> <span class="n">file</span> <span class="n">distributed</span> <span class="k">with</span><span class="o">,</span> <span class="nc">Hellorem</span> <span class="k">this</span> <span class="n">work</span> <span class="k">for</span> <span class="n">additional</span> <span class="n">information</span> <span class="n">regarding</span> <span class="n">copyright</span> <span class="n">ownership</span><span class="o">.,</span> <span class="nc">Hellorem</span> <span class="nc">The</span> <span class="nc">ASF</span> <span class="n">licenses</span> <span class="k">this</span> <span class="n">file</span> <span class="n">to</span> <span class="nc">You</span> <span class="n">under</span> <span class="n">the</span> <span class="nc">Apache</span> <span class="nc">License</span><span class="o">,</span> <span class="nc">Version</span> <span class="mf">2.0</span><span class="o">,</span> <span class="nc">Hellorem</span> <span class="o">(</span><span class="n">the</span> <span class="s">"License"</span><span class="o">);</span> <span class="n">you</span> <span class="n">may</span> <span class="n">not</span> <span class="n">use</span> <span class="k">this</span> <span class="n">file</span> <span class="n">except</span> <span class="n">in</span> <span class="n">compliance</span> <span class="k">with</span><span class="o">,</span> <span class="nc">Hellorem</span> <span class="n">the</span> <span class="nc">License</span><span class="o">.</span>  <span class="nc">You</span> <span class="n">may</span> <span class="n">obtain</span> <span class="n">a</span> <span class="n">copy</span> <span class="n">of</span> <span class="n">the</span> <span class="nc">License</span> <span class="n">at</span><span class="o">,</span> <span class="nc">Hellorem</span><span class="o">,</span> <span class="nc">Hellorem</span>    <span class="n">http</span><span class="o">://</span><span class="nv">www</span><span class="o">.</span><span class="py">apache</span><span class="o">.</span><span class="py">org</span><span class="o">/</span><span class="n">licenses</span><span class="o">/</span><span class="nc">LICENSE</span><span class="o">-</span><span class="mf">2.0</span><span class="o">,</span> <span class="nc">Hellorem</span><span class="o">,</span> <span class="nc">Hellorem</span> <span class="nc">Unless</span> <span class="n">required</span> <span class="n">by</span> <span class="n">applicable</span> <span class="n">law</span> <span class="n">or</span> <span class="n">agreed</span> <span class="n">to</span> <span class="n">in</span> <span class="n">writing</span><span class="o">,</span> <span class="n">software</span><span class="o">,</span> <span class="nc">Hellorem</span> <span class="n">distributed</span> <span class="n">under</span> <span class="n">the</span> <span class="nc">License</span> <span class="n">is</span> <span class="n">distributed</span> <span class="n">on</span> <span class="n">an</span> <span class="s">"AS IS"</span> <span class="nc">BASIS</span><span class="o">,,</span> <span class="nc">Hellorem</span> <span class="nc">WITHOUT</span> <span class="nc">WARRANTIES</span> <span class="nc">OR</span> <span class="nc">CONDITIONS</span> <span class="nc">OF</span> <span class="n">A</span><span class="o">...</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p><strong>在驱动程序中，预先拷贝了<code class="language-plaintext highlighter-rouge">MyClass.field</code>，<code class="language-plaintext highlighter-rouge">map</code>算子不再访问<code class="language-plaintext highlighter-rouge">MyClass</code>的实例。</strong></p>

<p>注意：Scala的<code class="language-plaintext highlighter-rouge">Serializable</code>实质上继承自<code class="language-plaintext highlighter-rouge">java.io.Serializable</code>。</p>

<h2 id="理解闭包">理解闭包</h2>

<p>在集群中执行代码时，一个关于Spark更难的事情是理解变量和方法的范围和生命周期。如下示例是一种常见的混淆变量和方法范围的案例。</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre></td><td class="rouge-code"><pre><span class="n">scala</span><span class="o">&gt;</span> <span class="k">var</span> <span class="n">counter</span> <span class="k">=</span> <span class="mi">0</span>
<span class="n">counter</span><span class="k">:</span> <span class="kt">Int</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">scala</span><span class="o">&gt;</span> <span class="k">var</span> <span class="n">distFile</span> <span class="k">=</span> <span class="nv">sc</span><span class="o">.</span><span class="py">textFile</span><span class="o">(</span><span class="s">"spark-shell.cmd"</span><span class="o">)</span>
<span class="n">distFile</span><span class="k">:</span> <span class="kt">org.apache.spark.rdd.RDD</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="n">spark</span><span class="o">-</span><span class="nv">shell</span><span class="o">.</span><span class="py">cmd</span> <span class="nc">MapPartitionsRDD</span><span class="o">[</span><span class="err">6</span><span class="o">]</span> <span class="n">at</span> <span class="n">textFile</span> <span class="n">at</span> <span class="o">&lt;</span><span class="n">console</span><span class="k">&gt;:</span><span class="mi">25</span>
<span class="n">scala</span><span class="o">&gt;</span> <span class="nv">distFile</span><span class="o">.</span><span class="py">foreach</span><span class="o">(</span><span class="n">line</span> <span class="k">=&gt;</span> <span class="n">counter</span> <span class="o">+</span> <span class="mi">1</span><span class="o">)</span>
<span class="n">scala</span><span class="o">&gt;</span> <span class="nf">println</span><span class="o">(</span><span class="s">"Counter = "</span> <span class="o">+</span> <span class="n">counter</span><span class="o">)</span>
<span class="nc">Counter</span> <span class="k">=</span> <span class="mi">0</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>上述代码行为是不确定的，并且可能无法按预期正常工作。Spark执行作业时，会分解RDD操作到每个执行者。在执行之前，Spark计算task的closure。而闭包包含了RDD上的执行者必须能够访问的变量和方法。闭包被序列化发送到每个执行器。</p>

<p>闭包的变量副本发给了每个执行器，当counter被foreach函数引用时，它已经不再是驱动节点的counter。虽然在驱动节点仍然有一个counter在内存中，但是对执行器是不可见的，执行器访问到的只是序列化的闭包提供的副本，foreach中被累加的counter也只是执行器局部访问的副本。所以counter仍为0。</p>

<p>在本地模式，某些情况下的foreach功能实际上是在同一JVM上的驱动程序执行的，并引用了同一原始的计数器，实际上可能更新。</p>

<p>为了确保在这些场景下达到目的，可以使用Accumulator累加器。当一个执行的任务分配到集群中的各个worker节点时，Spark的累加器提供了安全的更新变量机制。</p>

<p>一般情况下，闭包结构或本地定义的方法，不应该用于修改全局变量。</p>

<p>如<code class="language-plaintext highlighter-rouge">rdd.foreach(println)</code>或<code class="language-plaintext highlighter-rouge">rdd.map(println)</code>是不能保证产生预期输出的，如在集群模式下，<code class="language-plaintext highlighter-rouge">println</code>使用的<code class="language-plaintext highlighter-rouge">stdout</code>是执行器本地的<code class="language-plaintext highlighter-rouge">stdout</code>，在驱动程序上是看不到效果的。打印输出可以使用如下两种方法，</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre></td><td class="rouge-code"><pre><span class="nv">distFile</span><span class="o">.</span><span class="py">collect</span><span class="o">().</span><span class="py">foreach</span><span class="o">(</span><span class="n">x</span> <span class="k">=&gt;</span> <span class="nf">println</span><span class="o">(</span><span class="n">x</span><span class="o">))</span>
<span class="nv">distFile</span><span class="o">.</span><span class="py">take</span><span class="o">(</span><span class="mi">10</span><span class="o">).</span><span class="py">foreach</span><span class="o">(</span><span class="n">x</span> <span class="k">=&gt;</span> <span class="nf">println</span><span class="o">(</span><span class="n">x</span><span class="o">))</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>其中，<code class="language-plaintext highlighter-rouge">take</code>方法限制了聚合数据的元素的数量。</p>

<h2 id="使用key-value对">使用Key-Value对</h2>

<p>虽然大多数Spark操作工作在包含任何类型对象的RDDs上，只有少数特殊的操作可以用于Key-Value对的RDDs。最常见的是分布式“shuffle”操作，如通过元素的key来进行<code class="language-plaintext highlighter-rouge">grouping</code>或<code class="language-plaintext highlighter-rouge">aggregating</code>操作。</p>

<p>在Scala中，这些操作时可用Tuple2对象。在<code class="language-plaintext highlighter-rouge">PairRDDFunctions</code>类中该Key-Value对操作有效，其中围绕元组的RDD自动包装。</p>

<p>例如，下面代码使用的Key-Value对的 <code class="language-plaintext highlighter-rouge">reduceByKey</code>操作统计文本文件的单词数量。</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
</pre></td><td class="rouge-code"><pre><span class="n">scala</span><span class="o">&gt;</span> <span class="k">val</span> <span class="nv">distFile</span> <span class="k">=</span> <span class="nv">sc</span><span class="o">.</span><span class="py">textFile</span><span class="o">(</span><span class="s">"spark-shell.cmd"</span><span class="o">)</span>
<span class="n">distFile</span><span class="k">:</span> <span class="kt">org.apache.spark.rdd.RDD</span><span class="o">[</span><span class="kt">String</span><span class="o">]</span> <span class="k">=</span> <span class="n">spark</span><span class="o">-</span><span class="nv">shell</span><span class="o">.</span><span class="py">cmd</span> <span class="nc">MapPartitionsRDD</span><span class="o">[</span><span class="err">10</span><span class="o">]</span> <span class="n">at</span> <span class="n">textFile</span> <span class="n">at</span> <span class="o">&lt;</span><span class="n">console</span><span class="k">&gt;:</span><span class="mi">25</span>

<span class="n">scala</span><span class="o">&gt;</span> <span class="k">val</span> <span class="nv">pairs</span> <span class="k">=</span> <span class="nv">distFile</span><span class="o">.</span><span class="py">flatMap</span><span class="o">(</span><span class="n">l</span> <span class="k">=&gt;</span> <span class="nv">l</span><span class="o">.</span><span class="py">split</span><span class="o">(</span><span class="s">" "</span><span class="o">)).</span><span class="py">map</span><span class="o">(</span><span class="n">w</span> <span class="k">=&gt;</span> <span class="o">(</span><span class="n">w</span><span class="o">,</span> <span class="mi">1</span><span class="o">))</span>
<span class="n">pairs</span><span class="k">:</span> <span class="kt">org.apache.spark.rdd.RDD</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">)]</span> <span class="k">=</span> <span class="nc">MapPartitionsRDD</span><span class="o">[</span><span class="err">13</span><span class="o">]</span> <span class="n">at</span> <span class="n">map</span> <span class="n">at</span> <span class="o">&lt;</span><span class="n">console</span><span class="k">&gt;:</span><span class="mi">27</span>

<span class="n">scala</span><span class="o">&gt;</span> <span class="k">val</span> <span class="nv">counts</span> <span class="k">=</span> <span class="nv">pairs</span><span class="o">.</span><span class="py">reduceByKey</span><span class="o">((</span><span class="n">s</span><span class="o">,</span> <span class="n">n</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="n">s</span> <span class="o">+</span> <span class="n">n</span><span class="o">)</span>
<span class="n">counts</span><span class="k">:</span> <span class="kt">org.apache.spark.rdd.RDD</span><span class="o">[(</span><span class="kt">String</span>, <span class="kt">Int</span><span class="o">)]</span> <span class="k">=</span> <span class="nc">ShuffledRDD</span><span class="o">[</span><span class="err">14</span><span class="o">]</span> <span class="n">at</span> <span class="n">reduceByKey</span> <span class="n">at</span> <span class="o">&lt;</span><span class="n">console</span><span class="k">&gt;:</span><span class="mi">29</span>

<span class="n">scala</span><span class="o">&gt;</span> <span class="nv">counts</span><span class="o">.</span><span class="py">take</span><span class="o">(</span><span class="mi">10</span><span class="o">).</span><span class="py">foreach</span><span class="o">((</span><span class="n">w</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="nf">println</span><span class="o">(</span><span class="n">w</span><span class="o">))</span>
<span class="o">(</span><span class="n">entry</span><span class="o">,</span><span class="mi">1</span><span class="o">)</span>
<span class="o">(</span><span class="nc">Unless</span><span class="o">,</span><span class="mi">1</span><span class="o">)</span>
<span class="o">(</span><span class="k">this</span><span class="o">,</span><span class="mi">3</span><span class="o">)</span>
<span class="o">(</span><span class="n">licenses</span><span class="o">,</span><span class="mi">1</span><span class="o">)</span>
<span class="o">(</span><span class="n">under</span><span class="o">,</span><span class="mi">4</span><span class="o">)</span>
<span class="o">(</span><span class="nc">KIND</span><span class="o">,,</span><span class="mi">1</span><span class="o">)</span>
<span class="o">(</span><span class="n">is</span><span class="o">,</span><span class="mi">2</span><span class="o">)</span>
<span class="o">(</span><span class="n">polluting</span><span class="o">,</span><span class="mi">1</span><span class="o">)</span>
<span class="o">(</span><span class="n">rem</span><span class="o">,</span><span class="mi">18</span><span class="o">)</span>
<span class="o">(</span><span class="nc">CONDITIONS</span><span class="o">,</span><span class="mi">1</span><span class="o">)</span>

</pre></td></tr></tbody></table></code></pre></div></div>

<p>也可以使用<code class="language-plaintext highlighter-rouge">counts.sortByKey()</code>来按照字母表顺序排序。</p>

<div class="language-scala highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre></td><td class="rouge-code"><pre><span class="n">scala</span><span class="o">&gt;</span> <span class="nv">counts</span><span class="o">.</span><span class="py">sortByKey</span><span class="o">().</span><span class="py">take</span><span class="o">(</span><span class="mi">10</span><span class="o">).</span><span class="py">foreach</span><span class="o">((</span><span class="n">w</span><span class="o">)</span> <span class="k">=&gt;</span> <span class="nf">println</span><span class="o">(</span><span class="n">w</span><span class="o">))</span>
<span class="o">(,</span><span class="mi">8</span><span class="o">)</span>
<span class="o">(</span><span class="s">"%~dp0spark-shell2.cmd"</span><span class="o">,</span><span class="mi">1</span><span class="o">)</span>
<span class="o">(</span><span class="s">"AS,1)
("</span><span class="nc">License</span><span class="err">"</span><span class="o">);,</span><span class="mi">1</span><span class="o">)</span>
<span class="o">(%*,</span><span class="mi">1</span><span class="o">)</span>
<span class="o">((</span><span class="nc">ASF</span><span class="o">),</span><span class="mi">1</span><span class="o">)</span>
<span class="o">((</span><span class="n">the</span><span class="o">,</span><span class="mi">1</span><span class="o">)</span>
<span class="o">(/</span><span class="n">C</span><span class="o">,</span><span class="mi">1</span><span class="o">)</span>
<span class="o">(/</span><span class="n">E</span><span class="o">,</span><span class="mi">1</span><span class="o">)</span>
<span class="o">(/</span><span class="n">V</span><span class="o">,</span><span class="mi">1</span><span class="o">)</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>注意：使用自定义对象作为Key-Value对操作的key时，必须确保自定义<code class="language-plaintext highlighter-rouge">equal()</code>方法有一个<code class="language-plaintext highlighter-rouge">hashCode()</code>方法相匹配。</p>


                <hr style="visibility: hidden;">
                <ul class="pager">
                    
                    
                    <li class="next">
                        <a href="/2019/12/12/spark-rdd-operator/" data-toggle="tooltip" data-placement="top" title="Spark RDD 2 --- 操作">
                        Next<br>
                        <span>Spark RDD 2 --- 操作</span>
                        </a>
                    </li>
                    
                </ul>
                <hr style="visibility: hidden;">

                
                <!-- disqus 评论框 start -->
                <div class="comment">
                    <div id="disqus_thread" class="disqus-thread"></div>
                </div>
                <!-- disqus 评论框 end -->
                

                
            </div>  

    <!-- Side Catalog Container -->
        
            <div class="
                col-lg-2 col-lg-offset-0
                visible-lg-block
                sidebar-container
                catalog-container">
                <div class="side-catalog">
                    <hr class="hidden-sm hidden-xs">
                    <h5>
                        <a class="catalog-toggle" href="#">CATALOG</a>
                    </h5>
                    <ul class="catalog-body"></ul>
                </div>
            </div>
        

    <!-- Sidebar Container -->
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                sidebar-container">

                <!-- Featured Tags -->
                


<section>
    
        <hr class="hidden-sm hidden-xs">
    
    <h5><a href="/archive/">FEATURED TAGS</a></h5>
    <div class="tags">
        
        
        
        
        
        
                <a data-sort="0025" 
                    href="/archive/?tag=Spark"
                    title="Spark"
                    rel="10">Spark</a>
        
                <a data-sort="0025" 
                    href="/archive/?tag=Docker"
                    title="Docker"
                    rel="10">Docker</a>
        
                <a data-sort="0031" 
                    href="/archive/?tag=Linux"
                    title="Linux"
                    rel="4">Linux</a>
        
                <a data-sort="0031" 
                    href="/archive/?tag=RDD"
                    title="RDD"
                    rel="4">RDD</a>
        
                <a data-sort="0031" 
                    href="/archive/?tag=Vert.x"
                    title="Vert.x"
                    rel="4">Vert.x</a>
        
                <a data-sort="0031" 
                    href="/archive/?tag=vertx-core"
                    title="vertx-core"
                    rel="4">vertx-core</a>
        
                <a data-sort="0033" 
                    href="/archive/?tag=%E3%80%8A%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97--%E5%8E%9F%E7%90%86%E3%80%81%E7%AE%97%E6%B3%95%E4%B8%8E%E7%B3%BB%E7%BB%9F%E3%80%8B"
                    title="《分布式计算--原理、算法与系统》"
                    rel="2">《分布式计算--原理、算法与系统》</a>
        
                <a data-sort="0033" 
                    href="/archive/?tag=%E5%85%AC%E5%B9%B3%E8%B0%83%E5%BA%A6"
                    title="公平调度"
                    rel="2">公平调度</a>
        
                <a data-sort="0033" 
                    href="/archive/?tag=%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97"
                    title="分布式计算"
                    rel="2">分布式计算</a>
        
                <a data-sort="0033" 
                    href="/archive/?tag=%E7%B4%AF%E5%8A%A0%E5%99%A8"
                    title="累加器"
                    rel="2">累加器</a>
        
                <a data-sort="0033" 
                    href="/archive/?tag=FIFO%E8%B0%83%E5%BA%A6"
                    title="FIFO调度"
                    rel="2">FIFO调度</a>
        
                <a data-sort="0033" 
                    href="/archive/?tag=JVM"
                    title="JVM"
                    rel="2">JVM</a>
        
                <a data-sort="0033" 
                    href="/archive/?tag=Java"
                    title="Java"
                    rel="2">Java</a>
        
                <a data-sort="0033" 
                    href="/archive/?tag=Spark+Standalone"
                    title="Spark Standalone"
                    rel="2">Spark Standalone</a>
        
                <a data-sort="0033" 
                    href="/archive/?tag=Spark+Streaming"
                    title="Spark Streaming"
                    rel="2">Spark Streaming</a>
        
                <a data-sort="0033" 
                    href="/archive/?tag=container"
                    title="container"
                    rel="2">container</a>
        
                <a data-sort="0033" 
                    href="/archive/?tag=docker+image"
                    title="docker image"
                    rel="2">docker image</a>
        
                <a data-sort="0033" 
                    href="/archive/?tag=nsenter"
                    title="nsenter"
                    rel="2">nsenter</a>
        
                <a data-sort="0033" 
                    href="/archive/?tag=sudo"
                    title="sudo"
                    rel="2">sudo</a>
    </div>
</section>


                <!-- Friends Blog -->
                
<hr>
<h5>FRIENDS</h5>
<ul class="list-inline">
  
</ul>

            </div>
        </div>
    </div>
</article>

<!-- add support for mathjax by voleking-->






<!-- disqus 公共JS代码 start (一个网页只需插入一次) -->
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES * * */
    var disqus_shortname = "cheneyyin";
    var disqus_identifier = "/2019/12/06/spark-rdd-basic";
    var disqus_url = "http://localhost:4000/2019/12/06/spark-rdd-basic/";

    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<!-- disqus 公共JS代码 end -->




<!-- async load function -->
<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>
<!-- anchor-js, Doc:http://bryanbraun.github.io/anchorjs/ -->
<script>
    async("//cdnjs.cloudflare.com/ajax/libs/anchor-js/1.1.1/anchor.min.js",function(){
        anchors.options = {
          visible: 'hover',
          placement: 'right',
          // icon: '#'
        };
        anchors.add().remove('.intro-header h1').remove('.subheading').remove('.sidebar-container h5');
    })
</script>
<style>
    /* place left on bigger screen */
    @media all and (min-width: 800px) {
        .anchorjs-link{
            position: absolute;
            left: -0.75em;
            font-size: 1.1em;
            margin-top : -0.1em;
        }
    }
</style>



    <!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <!-- SNS Link -->
                


<ul class="list-inline text-center">


  
  
  
  <li>
    <a target="_blank" href="https://www.zhihu.com/people/cheney-yin-77">
      <span class="fa-stack fa-lg">
        <i class="fa fa-circle fa-stack-2x"></i>
        <i class="fa  fa-stack-1x fa-inverse">知</i>
      </span>
    </a>
  </li>
  
  
  
  
  <li>
    <a target="_blank" href="https://github.com/CheneyYin">
      <span class="fa-stack fa-lg">
        <i class="fa fa-circle fa-stack-2x"></i>
        <i class="fa fa-github fa-stack-1x fa-inverse"></i>
      </span>
    </a>
  </li>
  
  
</ul>

                <p class="copyright text-muted">
                    Copyright &copy; Cheney.Yin Blog 2023
                    <br>
                    Powered by <a href="http://cheneyyin.github.io">Cheney.Yin Blog</a> |
                    <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="100px"
                        height="20px"
                        src="https://ghbtns.com/github-btn.html?user=CheneyYin&repo=cheneyyin.github.io&type=star&count=true">
                    </iframe>
                </p>
            </div>
        </div>
    </div>
</footer>

<!-- jQuery -->
<script src="/js/jquery.min.js "></script>

<!-- Bootstrap Core JavaScript -->
<!-- Currently, only navbar scroll-down effect at desktop still depends on this -->
<script src="/js/bootstrap.min.js "></script>

<!-- Custom Theme JavaScript -->
<script src="/js/hux-blog.min.js "></script>

<!-- Simple Jekyll Search -->
<script src="/js/simple-jekyll-search.min.js"></script>

<!-- Service Worker -->

<script src="/js/snackbar.js "></script>
<script src="/js/sw-registration.js "></script>


<!-- async load function -->
<script>
    function async(u, c) {
        var d = document, t = 'script',
            o = d.createElement(t),
            s = d.getElementsByTagName(t)[0];
        o.src = u;
        if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
        s.parentNode.insertBefore(o, s);
    }
</script>

<!--
     Because of the native support for backtick-style fenced code blocks
     right within the Markdown is landed in Github Pages,
     From V1.6, There is no need for Highlight.js,
     so Huxblog drops it officially.

     - https://github.com/blog/2100-github-pages-now-faster-and-simpler-with-jekyll-3-0
     - https://help.github.com/articles/creating-and-highlighting-code-blocks/
     - https://github.com/jneen/rouge/wiki/list-of-supported-languages-and-lexers
-->
<!--
    <script>
        async("http://cdn.bootcss.com/highlight.js/8.6/highlight.min.js", function(){
            hljs.initHighlightingOnLoad();
        })
    </script>
    <link href="http://cdn.bootcss.com/highlight.js/8.6/styles/github.min.css" rel="stylesheet">
-->







<!--fastClick.js -->
<script>
    async("//cdnjs.cloudflare.com/ajax/libs/fastclick/1.0.6/fastclick.min.js", function () {
        var $nav = document.querySelector("nav");
        if ($nav) FastClick.attach($nav);
    })
</script>

<!-- Google Analytics -->

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-KMZ19PZE4D"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-KMZ19PZE4D');
</script>



<!-- Baidu Tongji -->



<!-- Side Catalog -->

<script type="text/javascript">
    function generateCatalog(selector) {

        // interop with multilangual 
        if ('' == 'true') {
            _containerSelector = 'div.post-container.active'
        } else {
            _containerSelector = 'div.post-container'
        }

        // init
        var P = $(_containerSelector), a, n, t, l, i, c;
        a = P.find('h1,h2,h3,h4,h5,h6');

        // clean
        $(selector).html('')

        // appending
        a.each(function () {
            n = $(this).prop('tagName').toLowerCase();
            i = "#" + $(this).prop('id');
            t = $(this).text();
            c = $('<a href="' + i + '" rel="nofollow">' + t + '</a>');
            l = $('<li class="' + n + '_nav"></li>').append(c);
            $(selector).append(l);
        });
        return true;
    }

    generateCatalog(".catalog-body");

    // toggle side catalog
    $(".catalog-toggle").click((function (e) {
        e.preventDefault();
        $('.side-catalog').toggleClass("fold")
    }))

    /*
     * Doc: https://github.com/davist11/jQuery-One-Page-Nav
     * Fork by Hux to support padding
     */
    async("/js/jquery.nav.js", function () {
        $('.catalog-body').onePageNav({
            currentClass: "active",
            changeHash: !1,
            easing: "swing",
            filter: "",
            scrollSpeed: 700,
            scrollOffset: 0,
            scrollThreshold: .2,
            begin: null,
            end: null,
            scrollChange: null,
            padding: 80
        });
    });
</script>



<!-- Multi-Lingual -->


<!-- Simple Jekyll Search -->
<script>
    // https://stackoverflow.com/questions/1912501/unescape-html-entities-in-javascript
    function htmlDecode(input) {
        var e = document.createElement('textarea');
        e.innerHTML = input;
        // handle case of empty input
        return e.childNodes.length === 0 ? "" : e.childNodes[0].nodeValue;
    }

    SimpleJekyllSearch({
        searchInput: document.getElementById('search-input'),
        resultsContainer: document.getElementById('search-results'),
        json: '/search.json',
        searchResultTemplate: '<div class="post-preview item"><a href="{url}"><h2 class="post-title">{title}</h2><h3 class="post-subtitle">{subtitle}</h3><hr></a></div>',
        noResultsText: 'No results',
        limit: 50,
        fuzzy: false,
        // a hack to get escaped subtitle unescaped. for some reason, 
        // post.subtitle w/o escape filter nuke entire search.
        templateMiddleware: function (prop, value, template) {
            if (prop === 'subtitle' || prop === 'title') {
                if (value.indexOf("code")) {
                    return htmlDecode(value);
                } else {
                    return value;
                }
            }
        }
    });

    $(document).ready(function () {
        var $searchPage = $('.search-page');
        var $searchOpen = $('.search-icon');
        var $searchClose = $('.search-icon-close');
        var $searchInput = $('#search-input');
        var $body = $('body');

        $searchOpen.on('click', function (e) {
            e.preventDefault();
            $searchPage.toggleClass('search-active');
            var prevClasses = $body.attr('class') || '';
            setTimeout(function () {
                $body.addClass('no-scroll');
            }, 400)

            if ($searchPage.hasClass('search-active')) {
                $searchClose.on('click', function (e) {
                    e.preventDefault();
                    $searchPage.removeClass('search-active');
                    $body.attr('class', prevClasses);  // from closure 
                });
                $searchInput.focus();
            }
        });
    });
</script>

</body>

</html>
